# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oPQF7nwi1_MhcX8Y3mVwjeesrsNkxbf0
"""

from keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D
from keras.models import Model
from keras.applications.vgg19 import VGG19
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import Adam
from keras.callbacks import EarlyStopping
from keras.utils import plot_model
from google.colab import drive
drive.mount('/content/drive')

class_names = ['benign', 'malignant']

tf.config.optimizer.set_experimental_options({"auto_mixed_precision": True})

def create_autoencoder(input_shape):
    input_img = Input(shape=input_shape)
    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)
    x = MaxPooling2D((2, 2), padding='same')(x)
    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)
    x = MaxPooling2D((2, 2), padding='same')(x)
    encoded = Flatten()(x)
    return Model(input_img, encoded)

def create_vgg19(input_shape):
    base_model = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)
    for layer in base_model.layers:
        layer.trainable = False
    return base_model

def combined_model(input_shape, num_classes):
    autoencoder = create_autoencoder(input_shape)
    vgg19 = create_vgg19(input_shape)
    encoded_input = autoencoder.input
    encoded_features = autoencoder(encoded_input)
    vgg19_output = vgg19(encoded_input)
    vgg19_output_flattened = Flatten()(vgg19_output)
    combined_features = Dense(256, activation='relu')(vgg19_output_flattened)
    classification_output = Dense(num_classes, activation='softmax')(combined_features)
    return Model(encoded_input, classification_output)

input_shape = (224, 224, 3)
num_classes = 2  # Number of classes: 'benign' and 'malignant'
model = combined_model(input_shape, num_classes)

train_datagen = ImageDataGenerator(rescale=1./255)
train_generator = train_datagen.flow_from_directory(
    '/content/drive/MyDrive/val-20240305T062525Z-001/datasets for/train',
    target_size=(224, 224),
    batch_size=91,
    class_mode='categorical')

val_datagen = ImageDataGenerator(rescale=1./255)
validation_generator = val_datagen.flow_from_directory(
    '/content/drive/MyDrive/val-20240305T062525Z-001/datasets for/val',
    target_size=(224, 224),
    batch_size=91,
    class_mode='categorical')

test_datagen = ImageDataGenerator(rescale=1./255)
test_generator = test_datagen.flow_from_directory(
    '/content/drive/MyDrive/val-20240305T062525Z-001/datasets for/test',
    target_size=(224, 224),
    batch_size=91,
    class_mode='categorical')

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

import numpy as np
import matplotlib.pyplot as plt
from keras.callbacks import EarlyStopping, ModelCheckpoint

early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1)
checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)

# Train the model
history = model.fit(
    train_generator,
    epochs=5,
    steps_per_epoch=len(train_generator),
    validation_data=validation_generator,
    validation_steps=len(validation_generator),
    callbacks=[early_stopping, checkpoint]
)

test_datagen = ImageDataGenerator(rescale=1./255)
test_generator = test_datagen.flow_from_directory(
    '/content/drive/MyDrive/val-20240305T062525Z-001/datasets for/test',
    target_size=(224, 224),
    batch_size=91,
    class_mode='categorical')

loss, accuracy = model.evaluate_generator(test_generator, steps=test_generator.samples // 32)
print("Test Loss:", loss)
print("Test Accuracy:", accuracy)

loss,accuracy=model.evaluate(train_generator)
accuracy*100
val_loss,val_accuracy=model.evaluate(validation_generator)
val_accuracy*100
test_loss,test_accuracy=model.evaluate(test_generator)
test_accuracy*100

def predict(model, img):
    img_array = tf.keras.preprocessing.image.img_to_array(images[i])
    img_array = tf.expand_dims(img_array, 0)

    predictions = model.predict(img_array)

    predicted_class = class_names[np.argmax(predictions[0])]
    confidence = round(100 * (np.max(predictions[0])), 2)
    return predicted_class, confidence

for image_batch, label_batch in test_generator:
    print(image_batch.shape)
    break

class_names = ['benign', 'malignant']
print(class_names)

def predict(model, img):
    img_array = tf.keras.preprocessing.image.img_to_array(images[i])
    img_array = tf.expand_dims(img_array, 0)

    predictions = model.predict(img_array)

    predicted_class = class_names[np.argmax(predictions[0])]
    confidence = round(100 * (np.max(predictions[0])), 2)
    return predicted_class, confidence

import numpy as np
import matplotlib.pyplot as plt

for images_batch, labels_batch in test_generator:
    first_image = images_batch[0]
    first_label = int(np.argmax(labels_batch[0]))  # Convert to integer using argmax

    print("First image to predict")
    plt.imshow(first_image)
    plt.show()
    print("Actual label:", class_names[first_label])

    batch_prediction = model.predict(images_batch)
    print("Predicted label:", class_names[np.argmax(batch_prediction[0])])
    break

import numpy as np
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
predictions = model.predict(test_generator)
predicted_classes = np.argmax(predictions, axis=1)
true_classes = test_generator.classes
class_labels = list(test_generator.class_indices.keys())
print("Classification Report:")
print(classification_report(true_classes, predicted_classes, target_names=class_labels))
conf_matrix = confusion_matrix(true_classes, predicted_classes)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

class_names = train_generator.class_indices
def predict(model, img):
    predictions = model.predict(img)
    predicted_class = list(class_names.keys())[np.argmax(predictions)]
    confidence = round(100 * np.max(predictions), 2)
    return predicted_class, confidence

test_generator.reset()
Y_pred = model.predict(test_generator)
y_pred = np.argmax(Y_pred, axis=1)
cm = confusion_matrix(test_generator.classes, y_pred)
print('Confusion Matrix')
print(cm)

print('Classification Report')
target_names = list(class_names.keys())
print(classification_report(test_generator.classes, y_pred, target_names=target_names))

from sklearn.metrics import roc_curve, auc

# Calculate ROC curve for each class
fpr = dict()
tpr = dict()
roc_auc = dict()

# For each class
for i, class_name in enumerate(class_names):
    fpr[class_name], tpr[class_name], _ = roc_curve((test_generator.classes == i).astype(int), Y_pred[:, i])
    roc_auc[class_name] = auc(fpr[class_name], tpr[class_name])

# Plot ROC curve for each class
plt.figure(figsize=(10, 8))
for class_name in class_names:
    plt.plot(fpr[class_name], tpr[class_name], label=f'ROC curve (area = {roc_auc[class_name]:.2f}) for {class_name}')

plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

model.save('lun.py')

drive.mount('/content/drive')
!mv lun.h5 /content/drive/MyDrive/